{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf4f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (2.2.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.8 kB ? eta -:--:--\n",
      "     ------------------------------- ------ 51.2/60.8 kB 650.2 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 648.3 kB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.7 MB 9.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.1/8.7 MB 11.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.8/8.7 MB 14.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.6/8.7 MB 15.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.1/8.7 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.1/8.7 MB 15.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.5/8.7 MB 15.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.2/8.7 MB 15.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 14.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.4/8.7 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.8/8.7 MB 15.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.7 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.5/8.7 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 13.6 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.4/308.4 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/38.6 MB 16.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.3/38.6 MB 17.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.7/38.6 MB 15.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.8/38.6 MB 18.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.5/38.6 MB 17.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 4.4/38.6 MB 17.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 5.4/38.6 MB 18.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.3/38.6 MB 19.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.6/38.6 MB 20.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.7/38.6 MB 20.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.6/38.6 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.5/38.6 MB 21.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.4/38.6 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 12.6/38.6 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 13.1/38.6 MB 22.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.1/38.6 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 14.7/38.6 MB 22.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 15.5/38.6 MB 21.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 16.5/38.6 MB 21.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.3/38.6 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.2/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 19.1/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 20.1/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.9/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 21.8/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 22.9/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.6/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.8/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.8/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.7/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 27.6/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.6/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.3/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.4/38.6 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.3/38.6 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.2/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.1/38.6 MB 19.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.0/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.9/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.0/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.0/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.8/38.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 17.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191b15f0-f0e1-4ebf-89c3-79614ca325ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e855efb-feeb-49f6-97ae-f7dd26c69f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Age                        10000 non-null  int64  \n",
      " 1   Menstrual_Irregularity     10000 non-null  int64  \n",
      " 2   Chronic_Pain_Level         10000 non-null  float64\n",
      " 3   Hormone_Level_Abnormality  10000 non-null  int64  \n",
      " 4   Infertility                10000 non-null  int64  \n",
      " 5   BMI                        10000 non-null  float64\n",
      " 6   Diagnosis                  10000 non-null  int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 547.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Menstrual_Irregularity', 'Chronic_Pain_Level',\n",
       "       'Hormone_Level_Abnormality', 'Infertility', 'BMI', 'Diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"structured_endometriosis_data.csv\")\n",
    "\n",
    "# Display the first 2 rows of the dataset to get a quick look at the data\n",
    "data.head(2)\n",
    "\n",
    "# Generate summary statistics for numerical columns (count, mean, std, min, quartiles, max)\n",
    "data.describe()\n",
    "\n",
    "# Print concise information about the DataFrame: column names, non-null counts, and data types\n",
    "data.info()\n",
    "\n",
    "# Count the number of missing (NaN) values in each column\n",
    "data.isnull().sum()\n",
    "\n",
    "# Display the list of all column names in the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fdecaec-8f91-492a-bd68-006566b14c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                          0\n",
       "Menstrual_Irregularity       0\n",
       "Chronic_Pain_Level           0\n",
       "Hormone_Level_Abnormality    0\n",
       "Infertility                  0\n",
       "BMI                          0\n",
       "Diagnosis                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae82819-2274-40df-9234-cb3a6159d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts written: endo_preproc_v1.json, endo_dt_model_v1.json, endo_model_card_v1.md, endo_golden_examples_v1.json\n"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Helper to make JSON-safe\n",
    "def to_py(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    if isinstance(o, dict):\n",
    "        return {str(k): to_py(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        return [to_py(v) for v in o]\n",
    "    return o\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"structured_endometriosis_data.csv\")\n",
    "target_col = \"Diagnosis\"\n",
    "y = df[target_col].astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Split train/test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "numeric_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. Decision Tree with hyperparameter search\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"dt\", dt)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [3, 4, 5, 6, None],\n",
    "    \"dt__min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=\"f1\", n_jobs=-1\n",
    ")\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# 5. Choose threshold (favor recall on val set)\n",
    "val_proba = best_pipe.predict_proba(X_trainval)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_trainval, val_proba)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "mask = rec >= 0.85\n",
    "if mask.any():\n",
    "    idx = np.nanargmax(f1s[mask])\n",
    "    chosen_threshold = thr[max(0, np.where(mask)[0][idx] - 1)]\n",
    "else:\n",
    "    chosen_threshold = thr[np.nanargmax(f1s)] if len(thr) > 0 else 0.5\n",
    "chosen_threshold = float(chosen_threshold)\n",
    "\n",
    "# 6. Evaluate on test\n",
    "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= chosen_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, test_proba)),\n",
    "    \"precision\": float(precision_score(y_test, test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, test_pred))\n",
    "}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "metrics[\"specificity\"] = float(tn / (tn + fp + 1e-12))\n",
    "metrics[\"confusion_matrix\"] = {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "\n",
    "# 7. Export preprocessing manifest\n",
    "preprocessor.fit(X_trainval)\n",
    "num_imputer = preprocessor.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "num_impute_values = {c: float(v) for c, v in zip(numeric_cols, num_imputer.statistics_.tolist())}\n",
    "num_ranges = {c: {\"min\": float(X_trainval[c].min()), \"max\": float(X_trainval[c].max())} for c in numeric_cols}\n",
    "\n",
    "onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_vocabs = {}\n",
    "for c, cats in zip(categorical_cols, onehot.categories_):\n",
    "    cat_vocabs[c] = [None if (isinstance(v, float) and math.isnan(v)) else v for v in cats.tolist()]\n",
    "\n",
    "final_feature_order = []\n",
    "for col in numeric_cols:\n",
    "    final_feature_order.append({\"source\": col, \"kind\": \"numeric\"})\n",
    "for col, cats in cat_vocabs.items():\n",
    "    for cat in cats:\n",
    "        final_feature_order.append({\"source\": col, \"kind\": \"onehot\", \"category\": cat})\n",
    "\n",
    "preproc_manifest = {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"numeric_imputation\": num_impute_values,\n",
    "    \"numeric_ranges_train\": num_ranges,\n",
    "    \"categorical_vocabulary\": cat_vocabs,\n",
    "    \"final_feature_order\": final_feature_order,\n",
    "    \"preproc_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "# 8. Export Decision Tree structure\n",
    "def export_tree(tree_estimator):\n",
    "    tree = tree_estimator.tree_\n",
    "    nodes = []\n",
    "    for i in range(tree.node_count):\n",
    "        nodes.append({\n",
    "            \"feature_index\": int(tree.feature[i]),\n",
    "            \"threshold\": float(tree.threshold[i]),\n",
    "            \"left\": int(tree.children_left[i]),\n",
    "            \"right\": int(tree.children_right[i]),\n",
    "            \"value\": [float(x) for x in tree.value[i][0].tolist()],\n",
    "            \"is_leaf\": bool(tree.children_left[i] == -1 and tree.children_right[i] == -1),\n",
    "        })\n",
    "    return {\"nodes\": nodes}\n",
    "\n",
    "dt_est = best_pipe.named_steps[\"dt\"]\n",
    "dt_export = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": chosen_threshold,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "    \"tree\": export_tree(dt_est)\n",
    "}\n",
    "\n",
    "# 9. Model Card\n",
    "model_card = f\"\"\"# Endometriosis Classification Model Card\n",
    "\n",
    "**Model version:** v1  \n",
    "**Training date:** {datetime.utcnow().strftime(\"%Y-%m-%d\")}  \n",
    "\n",
    "### Best Params\n",
    "{best_params}\n",
    "\n",
    "### Metrics (Test Set)\n",
    "{json.dumps(metrics, indent=2)}\n",
    "\n",
    "### Notes\n",
    "Educational demo only — not medical advice.\n",
    "\"\"\"\n",
    "\n",
    "# 10. Golden Examples\n",
    "golden = []\n",
    "for i in range(min(10, len(X_test))):\n",
    "    row = X_test.iloc[i].to_dict()\n",
    "    golden.append({\n",
    "        \"input\": to_py(row),\n",
    "        \"pred_proba_high\": float(test_proba[i]),\n",
    "        \"label\": int(test_pred[i]),\n",
    "        \"true\": int(y_test[i])\n",
    "    })\n",
    "\n",
    "# 11. Save artifacts\n",
    "with open(\"endo_preproc_v1.json\",\"w\") as f: json.dump(to_py(preproc_manifest),f,indent=2)\n",
    "with open(\"endo_dt_model_v1.json\",\"w\") as f: json.dump(to_py(dt_export),f,indent=2)\n",
    "with open(\"endo_model_card_v1.md\",\"w\") as f: f.write(model_card)\n",
    "with open(\"endo_golden_examples_v1.json\",\"w\") as f: json.dump(to_py(golden),f,indent=2)\n",
    "\n",
    "print(\"Artifacts written: endo_preproc_v1.json, endo_dt_model_v1.json, endo_model_card_v1.md, endo_golden_examples_v1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2804c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts written: preproc_v1.json, dt_model_v1.json, model_card_v1.md, golden_examples_v1.json\n"
     ]
    }
   ],
   "source": [
    "import json, math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Helper to make JSON-safe\n",
    "def to_py(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    if isinstance(o, dict):\n",
    "        return {str(k): to_py(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple)):\n",
    "        return [to_py(v) for v in o]\n",
    "    return o\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"structured_endometriosis_data.csv\")\n",
    "target_col = \"Diagnosis\"\n",
    "y = df[target_col].astype(int).values\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Split categorical vs numeric\n",
    "categorical_cols, numeric_cols = [], []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        categorical_cols.append(c)\n",
    "    elif pd.api.types.is_integer_dtype(X[c]):\n",
    "        (categorical_cols if X[c].nunique() <= 10 else numeric_cols).append(c)\n",
    "    else:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "# 2. Split train/test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Preprocessing\n",
    "numeric_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# 4. Decision Tree with hyperparameter search\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", preprocessor),\n",
    "    (\"dt\", dt)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"dt__max_depth\": [3, 4, 5, 6, None],\n",
    "    \"dt__min_samples_leaf\": [1, 2, 5, 10]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=\"f1\", n_jobs=-1\n",
    ")\n",
    "grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_pipe = grid.best_estimator_\n",
    "best_params = grid.best_params_\n",
    "\n",
    "# 5. Choose threshold (favor recall on val set)\n",
    "val_proba = best_pipe.predict_proba(X_trainval)[:, 1]\n",
    "prec, rec, thr = precision_recall_curve(y_trainval, val_proba)\n",
    "f1s = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
    "mask = rec >= 0.85\n",
    "if mask.any():\n",
    "    idx = np.nanargmax(f1s[mask])\n",
    "    chosen_threshold = thr[max(0, np.where(mask)[0][idx] - 1)]\n",
    "else:\n",
    "    chosen_threshold = thr[np.nanargmax(f1s)] if len(thr) > 0 else 0.5\n",
    "chosen_threshold = float(chosen_threshold)\n",
    "\n",
    "# 6. Evaluate on test\n",
    "test_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "test_pred = (test_proba >= chosen_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, test_proba)),\n",
    "    \"pr_auc\": float(average_precision_score(y_test, test_proba)),\n",
    "    \"precision\": float(precision_score(y_test, test_pred)),\n",
    "    \"recall\": float(recall_score(y_test, test_pred)),\n",
    "    \"f1\": float(f1_score(y_test, test_pred))\n",
    "}\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, test_pred).ravel()\n",
    "metrics[\"specificity\"] = float(tn / (tn + fp + 1e-12))\n",
    "metrics[\"confusion_matrix\"] = {\"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)}\n",
    "\n",
    "# 7. Export preprocessing manifest\n",
    "preprocessor.fit(X_trainval)\n",
    "num_imputer = preprocessor.named_transformers_[\"num\"].named_steps[\"imputer\"]\n",
    "num_impute_values = {c: float(v) for c, v in zip(numeric_cols, num_imputer.statistics_.tolist())}\n",
    "num_ranges = {c: {\"min\": float(X_trainval[c].min()), \"max\": float(X_trainval[c].max())} for c in numeric_cols}\n",
    "\n",
    "onehot = preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "cat_vocabs = {}\n",
    "for c, cats in zip(categorical_cols, onehot.categories_):\n",
    "    cat_vocabs[c] = [None if (isinstance(v, float) and math.isnan(v)) else v for v in cats.tolist()]\n",
    "\n",
    "final_feature_order = []\n",
    "for col in numeric_cols:\n",
    "    final_feature_order.append({\"source\": col, \"kind\": \"numeric\"})\n",
    "for col, cats in cat_vocabs.items():\n",
    "    for cat in cats:\n",
    "        final_feature_order.append({\"source\": col, \"kind\": \"onehot\", \"category\": cat})\n",
    "\n",
    "preproc_manifest = {\n",
    "    \"numeric\": numeric_cols,\n",
    "    \"categorical\": categorical_cols,\n",
    "    \"numeric_imputation\": num_impute_values,\n",
    "    \"numeric_ranges_train\": num_ranges,\n",
    "    \"categorical_vocabulary\": cat_vocabs,\n",
    "    \"final_feature_order\": final_feature_order,\n",
    "    \"preproc_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "\n",
    "# 8. Export Decision Tree structure\n",
    "def export_tree(tree_estimator):\n",
    "    tree = tree_estimator.tree_\n",
    "    nodes = []\n",
    "    for i in range(tree.node_count):\n",
    "        nodes.append({\n",
    "            \"feature_index\": int(tree.feature[i]),\n",
    "            \"threshold\": float(tree.threshold[i]),\n",
    "            \"left\": int(tree.children_left[i]),\n",
    "            \"right\": int(tree.children_right[i]),\n",
    "            \"value\": [float(x) for x in tree.value[i][0].tolist()],\n",
    "            \"is_leaf\": bool(tree.children_left[i] == -1 and tree.children_right[i] == -1),\n",
    "        })\n",
    "    return {\"nodes\": nodes}\n",
    "\n",
    "dt_est = best_pipe.named_steps[\"dt\"]\n",
    "dt_export = {\n",
    "    \"params\": best_params,\n",
    "    \"threshold\": chosen_threshold,\n",
    "    \"metrics\": metrics,\n",
    "    \"model_version\": \"v1\",\n",
    "    \"trained_on\": datetime.utcnow().strftime(\"%Y-%m-%d\"),\n",
    "    \"tree\": export_tree(dt_est)\n",
    "}\n",
    "\n",
    "# 9. Model Card\n",
    "model_card = f\"\"\"# Heart Disease Decision Tree Model Card\n",
    "\n",
    "**Model version:** v1  \n",
    "**Training date:** {datetime.utcnow().strftime(\"%Y-%m-%d\")}  \n",
    "\n",
    "### Best Params\n",
    "{best_params}\n",
    "\n",
    "### Metrics (Test Set)\n",
    "{json.dumps(metrics, indent=2)}\n",
    "\n",
    "### Notes\n",
    "Educational demo only — not medical advice.\n",
    "\"\"\"\n",
    "\n",
    "# 10. Golden Examples\n",
    "golden = []\n",
    "for i in range(min(10, len(X_test))):\n",
    "    row = X_test.iloc[i].to_dict()\n",
    "    golden.append({\n",
    "        \"input\": to_py(row),\n",
    "        \"pred_proba_high\": float(test_proba[i]),\n",
    "        \"label\": int(test_pred[i]),\n",
    "        \"true\": int(y_test[i])\n",
    "    })\n",
    "\n",
    "# 11. Save artifacts\n",
    "with open(\"preproc_v1.json\",\"w\") as f: json.dump(to_py(preproc_manifest),f,indent=2)\n",
    "with open(\"dt_model_v1.json\",\"w\") as f: json.dump(to_py(dt_export),f,indent=2)\n",
    "with open(\"model_card_v1.md\",\"w\") as f: f.write(model_card)\n",
    "with open(\"golden_examples_v1.json\",\"w\") as f: json.dump(to_py(golden),f,indent=2)\n",
    "\n",
    "print(\"Artifacts written: preproc_v1.json, dt_model_v1.json, model_card_v1.md, golden_examples_v1.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ee4c53-5fc2-464f-a350-6ccbb7053222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Endometriosis Risk Assessment ===\n",
      "Please enter the following information:\n",
      "\n",
      "\n",
      "Menstrual_Irregularity options: 0, 1\n",
      "\n",
      "Hormone_Level_Abnormality options: 0, 1\n",
      "\n",
      "Infertility options: 0, 1\n",
      "\n",
      "==================================================\n",
      "PREDICTION RESULTS\n",
      "==================================================\n",
      "\n",
      "Input Summary:\n",
      "  • Age: 18.0\n",
      "  • Chronic_Pain_Level: 6.0\n",
      "  • BMI: 20.0\n",
      "  • Menstrual_Irregularity: 1\n",
      "  • Hormone_Level_Abnormality: 0\n",
      "  • Infertility: 1\n",
      "\n",
      "Decision Path:\n",
      "  Step 1: Hormone_Level_Abnormality=1 = 0.000 <= 0.500\n",
      "          -> Go left\n",
      "  Step 2: BMI = 20.000 <= 24.962\n",
      "          -> Go left\n",
      "  Step 3: Chronic_Pain_Level = 6.000 > 3.952\n",
      "          -> Go right\n",
      "  Step 4: Menstrual_Irregularity=1 = 1.000 > 0.500\n",
      "          -> Go right\n",
      "  Step 5: Infertility=1 = 1.000 > 0.500\n",
      "          -> Go right\n",
      "  Step 6: Age = 18.000 <= 39.500\n",
      "          -> Go left\n",
      "  Step 7: Chronic_Pain_Level = 6.000 > 4.761\n",
      "          -> Go right\n",
      "  Step 8: BMI = 20.000 <= 23.386\n",
      "          -> Go left\n",
      "  Step 9: Age = 18.000 <= 19.500\n",
      "          -> Go left\n",
      "  Step 10: Chronic_Pain_Level = 6.000 > 4.925\n",
      "          -> Go right\n",
      "  Step 11: Chronic_Pain_Level = 6.000 <= 7.998\n",
      "          -> Go left\n",
      "  Step 12: Reached leaf node #1000\n",
      "\n",
      "Prediction:\n",
      "  Probability of endometriosis: 0.0%\n",
      "  Threshold: 0.000\n",
      "  Classification: POSITIVE\n",
      "\n",
      "Model Performance (on test set):\n",
      "  • Precision: 40.8%\n",
      "  • Recall: 100.0%\n",
      "  • F1 Score: 58.0%\n",
      "\n",
      "DISCLAIMER: This is for educational purposes only.\n",
      "            Please consult healthcare professionals for medical advice.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Thank you for using the Endometriosis Risk Assessment tool!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreePredictor:\n",
    "    def __init__(self, preproc_path=\"endo_preproc_v1.json\", model_path=\"endo_dt_model_v1.json\"):\n",
    "        \"\"\"Initialize the predictor with preprocessing and model configs\"\"\"\n",
    "        with open(preproc_path, 'r') as f:\n",
    "            self.preproc = json.load(f)\n",
    "        with open(model_path, 'r') as f:\n",
    "            self.model = json.load(f)\n",
    "        \n",
    "        self.tree = self.model['tree']['nodes']\n",
    "        self.threshold = self.model['threshold']\n",
    "        \n",
    "    def get_user_input(self):\n",
    "        \"\"\"Collect user input for all features\"\"\"\n",
    "        print(\"\\n=== Endometriosis Risk Assessment ===\")\n",
    "        print(\"Please enter the following information:\\n\")\n",
    "        \n",
    "        user_data = {}\n",
    "        \n",
    "        # Collect numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            range_info = self.preproc['numeric_ranges_train'][col]\n",
    "            while True:\n",
    "                try:\n",
    "                    value = input(f\"{col} (typical range: {range_info['min']:.1f}-{range_info['max']:.1f}): \").strip()\n",
    "                    if value == \"\":\n",
    "                        # Use imputation value if empty\n",
    "                        user_data[col] = None\n",
    "                        print(f\"  -> Using median value: {self.preproc['numeric_imputation'][col]:.1f}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        user_data[col] = float(value)\n",
    "                        break\n",
    "                except ValueError:\n",
    "                    print(\"  Please enter a valid number or press Enter to use default\")\n",
    "        \n",
    "        # Collect categorical features\n",
    "        for col in self.preproc['categorical']:\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            print(f\"\\n{col} options: {', '.join(str(v) for v in vocab if v is not None)}\")\n",
    "            while True:\n",
    "                value = input(f\"{col}: \").strip()\n",
    "                if value == \"\":\n",
    "                    user_data[col] = None\n",
    "                    print(f\"  -> Using most frequent value\")\n",
    "                    break\n",
    "                # Try to convert to appropriate type\n",
    "                try:\n",
    "                    if value.isdigit():\n",
    "                        value = int(value)\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "                except:\n",
    "                    user_data[col] = value\n",
    "                    break\n",
    "        \n",
    "        return user_data\n",
    "    \n",
    "    def preprocess_input(self, user_data):\n",
    "        \"\"\"Apply preprocessing to user input\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Process numeric features\n",
    "        for col in self.preproc['numeric']:\n",
    "            value = user_data.get(col)\n",
    "            if value is None:\n",
    "                # Apply imputation\n",
    "                value = self.preproc['numeric_imputation'][col]\n",
    "            features.append(value)\n",
    "        \n",
    "        # Process categorical features with one-hot encoding\n",
    "        for col in self.preproc['categorical']:\n",
    "            value = user_data.get(col)\n",
    "            vocab = self.preproc['categorical_vocabulary'][col]\n",
    "            \n",
    "            # Create one-hot encoding\n",
    "            for category in vocab:\n",
    "                if value == category:\n",
    "                    features.append(1.0)\n",
    "                else:\n",
    "                    features.append(0.0)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def trace_tree(self, features):\n",
    "        \"\"\"Trace through the decision tree and return path\"\"\"\n",
    "        path = []\n",
    "        node_idx = 0  # Start at root\n",
    "        \n",
    "        while True:\n",
    "            node = self.tree[node_idx]\n",
    "            \n",
    "            if node['is_leaf']:\n",
    "                # Reached a leaf node\n",
    "                path.append({\n",
    "                    'node': node_idx,\n",
    "                    'type': 'leaf',\n",
    "                    'values': node['value']\n",
    "                })\n",
    "                break\n",
    "            \n",
    "            # Get feature name for this split\n",
    "            feature_idx = node['feature_index']\n",
    "            feature_info = self.preproc['final_feature_order'][feature_idx]\n",
    "            \n",
    "            # Make decision\n",
    "            feature_value = features[feature_idx]\n",
    "            threshold = node['threshold']\n",
    "            \n",
    "            if feature_value <= threshold:\n",
    "                next_node = node['left']\n",
    "                direction = 'left'\n",
    "                condition = f\"<= {threshold:.3f}\"\n",
    "            else:\n",
    "                next_node = node['right']\n",
    "                direction = 'right'\n",
    "                condition = f\"> {threshold:.3f}\"\n",
    "            \n",
    "            path.append({\n",
    "                'node': node_idx,\n",
    "                'type': 'decision',\n",
    "                'feature': feature_info,\n",
    "                'feature_value': feature_value,\n",
    "                'threshold': threshold,\n",
    "                'direction': direction,\n",
    "                'condition': condition\n",
    "            })\n",
    "            \n",
    "            node_idx = next_node\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def predict(self, features):\n",
    "        \"\"\"Make prediction using the decision tree\"\"\"\n",
    "        # Trace to leaf node\n",
    "        node_idx = 0\n",
    "        while not self.tree[node_idx]['is_leaf']:\n",
    "            node = self.tree[node_idx]\n",
    "            if features[node['feature_index']] <= node['threshold']:\n",
    "                node_idx = node['left']\n",
    "            else:\n",
    "                node_idx = node['right']\n",
    "        \n",
    "        # Get prediction from leaf node\n",
    "        leaf_values = self.tree[node_idx]['value']\n",
    "        # Convert to probability (positive class)\n",
    "        total = sum(leaf_values)\n",
    "        prob_positive = leaf_values[1] / total if total > 0 else 0\n",
    "        \n",
    "        return prob_positive\n",
    "    \n",
    "    def display_results(self, user_data, features, path, prob_positive):\n",
    "        \"\"\"Display the prediction results and decision path\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREDICTION RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Show input summary\n",
    "        print(\"\\nInput Summary:\")\n",
    "        for col, value in user_data.items():\n",
    "            if value is not None:\n",
    "                print(f\"  • {col}: {value}\")\n",
    "            else:\n",
    "                if col in self.preproc['numeric']:\n",
    "                    print(f\"  • {col}: {self.preproc['numeric_imputation'][col]:.1f} (imputed)\")\n",
    "                else:\n",
    "                    print(f\"  • {col}: (imputed)\")\n",
    "        \n",
    "        # Show decision path\n",
    "        print(\"\\nDecision Path:\")\n",
    "        for i, step in enumerate(path):\n",
    "            if step['type'] == 'decision':\n",
    "                feature = step['feature']\n",
    "                if feature['kind'] == 'numeric':\n",
    "                    feature_name = feature['source']\n",
    "                else:\n",
    "                    feature_name = f\"{feature['source']}={feature['category']}\"\n",
    "                \n",
    "                print(f\"  Step {i+1}: {feature_name} = {step['feature_value']:.3f} {step['condition']}\")\n",
    "                print(f\"          -> Go {step['direction']}\")\n",
    "            else:\n",
    "                print(f\"  Step {i+1}: Reached leaf node #{step['node']}\")\n",
    "        \n",
    "        # Show prediction\n",
    "        print(\"\\nPrediction:\")\n",
    "        print(f\"  Probability of endometriosis: {prob_positive:.1%}\")\n",
    "        \n",
    "        prediction = 1 if prob_positive >= self.threshold else 0\n",
    "        risk_level = \"POSITIVE\" if prediction == 1 else \"NEGATIVE\"\n",
    "        \n",
    "        print(f\"  Threshold: {self.threshold:.3f}\")\n",
    "        print(f\"  Classification: {risk_level}\")\n",
    "        \n",
    "        # Show model performance context\n",
    "        print(\"\\nModel Performance (on test set):\")\n",
    "        metrics = self.model['metrics']\n",
    "        print(f\"  • Precision: {metrics['precision']:.1%}\")\n",
    "        print(f\"  • Recall: {metrics['recall']:.1%}\")\n",
    "        print(f\"  • F1 Score: {metrics['f1']:.1%}\")\n",
    "        \n",
    "        print(\"\\nDISCLAIMER: This is for educational purposes only.\")\n",
    "        print(\"            Please consult healthcare professionals for medical advice.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the predictor\"\"\"\n",
    "    try:\n",
    "        # Initialize predictor\n",
    "        predictor = DecisionTreePredictor()\n",
    "        \n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_data = predictor.get_user_input()\n",
    "            \n",
    "            # Preprocess input\n",
    "            features = predictor.preprocess_input(user_data)\n",
    "            \n",
    "            # Trace decision path\n",
    "            path = predictor.trace_tree(features)\n",
    "            \n",
    "            # Get prediction\n",
    "            prob_positive = predictor.predict(features)\n",
    "            \n",
    "            # Display results\n",
    "            predictor.display_results(user_data, features, path, prob_positive)\n",
    "            \n",
    "            # Ask if user wants to continue\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            again = input(\"\\nWould you like to assess another case? (yes/no): \").strip().lower()\n",
    "            if again not in ['yes', 'y']:\n",
    "                print(\"\\nThank you for using the Endometriosis Risk Assessment tool!\")\n",
    "                break\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find required files. Please ensure 'endo_preproc_v1.json' and 'endo_dt_model_v1.json' exist.\")\n",
    "        print(f\"Details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1abf8c-9b51-4bf6-be7b-4aad1279d3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
